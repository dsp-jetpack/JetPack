--- raid.py	2020-08-18 11:32:32.000000000 -0400
+++ raid.py.new	2020-11-11 20:36:50.025343677 -0500
@@ -42,6 +42,11 @@
 
 METRICS = metrics_utils.get_metrics_logger(__name__)
 
+_CURRENT_RAID_CONTROLLER_MODE = "RAIDCurrentControllerMode"
+_REQUESTED_RAID_CONTROLLER_MODE = "RAIDRequestedControllerMode"
+_EHBA_MODE = "Enhanced HBA"
+_RAID_MODE = "RAID"
+
 RAID_LEVELS = {
     '0': {
         'min_disks': 1,
@@ -310,6 +315,70 @@
         raise exception.DracOperationError(error=exc)
 
 
+def set_raid_settings(node, controller_fqdd, settings):
+    """Sets the RAID configuration
+
+    It sets the pending_value parameter for each of the attributes
+    passed in. For the values to be applied, a config job must
+    be created.
+
+    :param node: an ironic node object.
+    :param controller_fqdd: the ID of the RAID controller.
+    :param settings: a dictionary containing the proposed values, with
+                     each key being the name of attribute and the value
+                     being the proposed value.
+    :returns: a dictionary containing:
+              - The is_commit_required key with a boolean value indicating
+              whether a config job must be created for the values to be
+              applied.
+              - The is_reboot_required key with a RebootRequired enumerated
+              value indicating whether the server must be rebooted for the
+              values to be applied. Possible values are true and false.
+    :raises: DRACOperationFailed on error reported back by the DRAC
+             interface
+    """
+    try:
+
+        drac_job.validate_job_queue(node)
+
+        client = drac_common.get_drac_client(node)
+        return client.set_raid_settings(controller_fqdd, settings)
+    except drac_exceptions.BaseClientException as exc:
+        LOG.error('DRAC driver failed to set raid settings '
+                  'on %(raid_controller_fqdd)s '
+                  'for node %(node_uuid)s. '
+                  'Reason: %(error)s.',
+                  {'raid_controller_fqdd': controller_fqdd,
+                   'node_uuid': node.uuid,
+                   'error': exc})
+        raise exception.DracOperationError(error=exc)
+
+
+def list_raid_settings(node):
+    """List the RAID configuration settings
+
+    :param node: an ironic node object.
+    :returns: a dictionary with the RAID settings using InstanceID as the
+              key. The attributes are RAIDEnumerableAttribute,
+              RAIDStringAttribute and RAIDIntegerAttribute objects.
+    :raises: DRACOperationFailed on error reported back by the DRAC
+             interface
+    """
+    try:
+
+        drac_job.validate_job_queue(node)
+
+        client = drac_common.get_drac_client(node)
+        return client.list_raid_settings()
+    except drac_exceptions.BaseClientException as exc:
+        LOG.error('DRAC driver failed to list raid settings '
+                  'for node %(node_uuid)s. '
+                  'Reason: %(error)s.',
+                  {'node_uuid': node.uuid,
+                   'error': exc})
+        raise exception.DracOperationError(error=exc)
+
+
 def change_physical_disk_state(node, mode=None,
                                controllers_to_physical_disk_ids=None):
     """Convert disks RAID status
@@ -377,7 +446,8 @@
 
 
 def _change_physical_disk_mode(node, mode=None,
-                               controllers_to_physical_disk_ids=None):
+                               controllers_to_physical_disk_ids=None,
+                               substep="completed"):
     """Physical drives conversion from RAID to JBOD or vice-versa.
 
     :param node: an ironic node object.
@@ -409,7 +479,7 @@
 
     return _commit_to_controllers(
         node,
-        controllers, substep='completed')
+        controllers, substep=substep)
 
 
 def abandon_config(node, raid_controller):
@@ -847,6 +917,70 @@
             'raid_config_parameters': raid_config_parameters}
 
 
+def _validate_volume_size(node, logical_disks):
+    new_physical_disks = list_physical_disks(node)
+    free_space_mb = {}
+    new_processed_volumes = []
+    for disk in new_physical_disks:
+        free_space_mb[disk] = disk.free_size_mb
+
+    for logical_disk in logical_disks:
+        selected_disks = [disk for disk in new_physical_disks
+                          if disk.id in logical_disk['physical_disks']]
+
+        spans_count = _calculate_spans(
+            logical_disk['raid_level'], len(selected_disks))
+
+        new_max_vol_size_mb = _max_volume_size_mb(
+            logical_disk['raid_level'],
+            selected_disks,
+            free_space_mb,
+            spans_count=spans_count)
+
+        if logical_disk['size_mb'] > new_max_vol_size_mb:
+            logical_disk['size_mb'] = new_max_vol_size_mb
+            LOG.info("Logical size does not match so calculating volume "
+                     "properties for current logical_disk")
+            _calculate_volume_props(
+                logical_disk, new_physical_disks, free_space_mb)
+            new_processed_volumes.append(logical_disk)
+
+    if new_processed_volumes:
+        return new_processed_volumes
+
+    return logical_disks
+
+
+def _switch_to_raid_mode(node, controller_fqdd):
+    """Convert the controller mode from Enhanced HBA to RAID mode
+
+    :param node: an ironic node object
+    :param controller_fqdd: the ID of the RAID controller.
+    :returns: a dictionary containing
+              - The raid_controller key with a ID of the
+              RAID controller value.
+              - The is_commit_required needed key with a
+              boolean value indicating whether a config job must be created
+              for the values to be applied.
+              - The is_reboot_required key with a RebootRequired enumerated
+              value indicating whether the server must be rebooted to
+              switch the controller mode to RAID.
+    """
+    # wait for pending jobs to complete
+    drac_job.wait_for_job_completion(node)
+
+    raid_attr = "{}:{}".format(controller_fqdd,
+                               _REQUESTED_RAID_CONTROLLER_MODE)
+    settings = {raid_attr: _RAID_MODE}
+    settings_results = set_raid_settings(
+        node, controller_fqdd, settings)
+    controller = {
+        'raid_controller': controller_fqdd,
+        'is_reboot_required': settings_results['is_reboot_required'],
+        'is_commit_required': settings_results['is_commit_required']}
+    return controller
+
+
 def _commit_to_controllers(node, controllers, substep="completed"):
     """Commit changes to RAID controllers on the node.
 
@@ -891,8 +1025,17 @@
         driver_internal_info['raid_config_job_ids'] = []
 
     optional = drac_constants.RebootRequired.optional
-    all_realtime = all(cntlr['is_reboot_required'] == optional
-                       for cntlr in controllers)
+
+    # all realtime controllers
+    all_realtime = all(
+        (cntlr['is_reboot_required'] == optional)
+        and not(cntlr.get('is_ehba_mode'))
+        for cntlr in controllers)
+
+    # check any controller with ehba mode
+    any_ehba_controllers = any(
+        cntrl.get('is_ehba_mode') is True for cntrl in controllers)
+
     raid_config_job_ids = []
     raid_config_parameters = []
     if all_realtime:
@@ -904,6 +1047,35 @@
                 raid_config_job_ids=raid_config_job_ids,
                 raid_config_parameters=raid_config_parameters)
 
+    elif any_ehba_controllers:
+        commit_to_ehba_controllers = []
+        for controller in controllers:
+            if controller.get('is_ehba_mode'):
+                job_details = _create_config_job(
+                    node, controller=controller['raid_controller'],
+                    reboot=False, realtime=True,
+                    raid_config_job_ids=raid_config_job_ids,
+                    raid_config_parameters=raid_config_parameters)
+
+                ehba_controller = _switch_to_raid_mode(
+                    node, controller['raid_controller'])
+                commit_to_ehba_controllers.append(
+                    ehba_controller['raid_controller'])
+            else:
+                job_details = _create_config_job(
+                    node, controller=controller['raid_controller'],
+                    reboot=False, realtime=False,
+                    raid_config_job_ids=raid_config_job_ids,
+                    raid_config_parameters=raid_config_parameters)
+
+        for controller in commit_to_ehba_controllers:
+            LOG.debug("Create job with Reboot to apply configuration "
+                      "changes for ehba controllers")
+            job_details = _create_config_job(
+                node, controller=controller,
+                reboot=(controller == commit_to_ehba_controllers[-1]),
+                realtime=False, raid_config_job_ids=raid_config_job_ids,
+                raid_config_parameters=raid_config_parameters)
     else:
         for controller in controllers:
             mix_controller = controller['raid_controller']
@@ -935,6 +1107,57 @@
     return deploy_utils.get_async_step_return_state(node)
 
 
+def _create_virtual_disks(task, node):
+    logical_disks_to_create = node.driver_internal_info[
+        'logical_disks_to_create']
+
+    # Check valid properties attached to voiume after drives conversion
+    isVolValidationNeeded = node.driver_internal_info[
+        'volume_validation']
+    if isVolValidationNeeded:
+        logical_disks_to_create = _validate_volume_size(
+            node, logical_disks_to_create)
+
+    controllers = list()
+    for logical_disk in logical_disks_to_create:
+        controller = dict()
+        controller_cap = create_virtual_disk(
+            node,
+            raid_controller=logical_disk['controller'],
+            physical_disks=logical_disk['physical_disks'],
+            raid_level=logical_disk['raid_level'],
+            size_mb=logical_disk['size_mb'],
+            disk_name=logical_disk.get('name'),
+            span_length=logical_disk.get('span_length'),
+            span_depth=logical_disk.get('span_depth'))
+        controller['raid_controller'] = logical_disk['controller']
+        controller['is_reboot_required'] = controller_cap[
+            'is_reboot_required']
+        controller['is_commit_required'] = controller_cap[
+            'is_commit_required']
+        if controller not in controllers:
+            controllers.append(controller)
+
+    return _commit_to_controllers(node, controllers)
+
+
+def _controller_in_hba_mode(raid_settings, controller_fqdd):
+    controller_mode = raid_settings.get(
+        '{}:{}'.format(controller_fqdd, _CURRENT_RAID_CONTROLLER_MODE))
+
+    return _EHBA_MODE in controller_mode.current_value
+
+
+def _controller_supports_ehba_mode(settings, controller_fqdd):
+    raid_cntrl_attr = "{}:{}".format(controller_fqdd,
+                                     _CURRENT_RAID_CONTROLLER_MODE)
+    current_cntrl_mode = settings.get(raid_cntrl_attr)
+    if not current_cntrl_mode:
+        return False
+    else:
+        return _EHBA_MODE in current_cntrl_mode.possible_values
+
+
 def _get_disk_free_size_mb(disk, pending_delete):
     """Return the size of free space on the disk in MB.
 
@@ -1033,9 +1256,7 @@
             del disk['size_gb']
 
         if delete_existing:
-            controllers = self._delete_configuration_no_commit(task)
-        else:
-            controllers = list()
+            self._delete_configuration_no_commit(task)
 
         physical_disks = list_physical_disks(node)
         logical_disks = _find_configuration(logical_disks, physical_disks,
@@ -1055,45 +1276,34 @@
                     logical_disk['controller']].append(
                     physical_disk_name)
 
+        # adding logical_disks to driver_internal_info to create virtual disks
+        driver_internal_info = node.driver_internal_info
+        driver_internal_info[
+            "logical_disks_to_create"] = logical_disks_to_create
+
+        commit_results = None
         if logical_disks_to_create:
             LOG.debug(
                 "Converting physical disks configured to back RAID "
                 "logical disks to RAID mode for node %(node_uuid)s ",
                 {"node_uuid": node.uuid})
-            raid = drac_constants.RaidStatus.raid
-            _change_physical_disk_mode(
-                node, raid, controllers_to_physical_disk_ids)
-
-            LOG.debug("Waiting for physical disk conversion to complete "
-                      "for node %(node_uuid)s. ", {"node_uuid": node.uuid})
-            drac_job.wait_for_job_completion(node)
-
-            LOG.info(
-                "Completed converting physical disks configured to back RAID "
-                "logical disks to RAID mode for node %(node_uuid)s",
-                {'node_uuid': node.uuid})
+            raid_mode = drac_constants.RaidStatus.raid
+            commit_results = _change_physical_disk_mode(
+                node, raid_mode,
+                controllers_to_physical_disk_ids,
+                substep="create_virtual_disks")
 
-        controllers = list()
-        for logical_disk in logical_disks_to_create:
-            controller = dict()
-            controller_cap = create_virtual_disk(
-                node,
-                raid_controller=logical_disk['controller'],
-                physical_disks=logical_disk['physical_disks'],
-                raid_level=logical_disk['raid_level'],
-                size_mb=logical_disk['size_mb'],
-                disk_name=logical_disk.get('name'),
-                span_length=logical_disk.get('span_length'),
-                span_depth=logical_disk.get('span_depth'))
-            controller['raid_controller'] = logical_disk['controller']
-            controller['is_reboot_required'] = controller_cap[
-                'is_reboot_required']
-            controller['is_commit_required'] = controller_cap[
-                'is_commit_required']
-            if controller not in controllers:
-                controllers.append(controller)
+        volume_validation = True if commit_results else False
+        driver_internal_info['volume_validation'] = volume_validation
+        node.driver_internal_info = driver_internal_info
+        node.save()
 
-        return _commit_to_controllers(node, controllers)
+        if commit_results:
+            return commit_results
+        else:
+            LOG.debug("Controller does not support drives conversion "
+                      "so creating virtual disks")
+            return _create_virtual_disks(task, node)
 
     @METRICS.timer('DracRAID.delete_configuration')
     @base.clean_step(priority=0)
@@ -1207,6 +1417,8 @@
                         return self._convert_drives(task, node)
                 elif substep == 'physical_disk_conversion':
                     self._convert_drives(task, node)
+                elif substep == "create_virtual_disks":
+                    return _create_virtual_disks(task, node)
                 elif substep == 'completed':
                     self._complete_raid_substep(task, node)
             else:
@@ -1313,9 +1525,15 @@
         node = task.node
         controllers = list()
         drac_raid_controllers = list_raid_controllers(node)
+        drac_raid_settings = list_raid_settings(node)
         for cntrl in drac_raid_controllers:
             if _is_raid_controller(node, cntrl.id, drac_raid_controllers):
                 controller = dict()
+                if _controller_supports_ehba_mode(
+                        drac_raid_settings,
+                        cntrl.id) and _controller_in_hba_mode(
+                            drac_raid_settings, cntrl.id):
+                    controller['is_ehba_mode'] = True
                 controller_cap = _reset_raid_config(node, cntrl.id)
                 controller["raid_controller"] = cntrl.id
                 controller["is_reboot_required"] = controller_cap[
