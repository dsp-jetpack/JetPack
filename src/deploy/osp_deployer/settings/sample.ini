# Copyright (c) 2015-2017 Dell Inc. or its subsidiaries.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

######################################################################################
#                                                                                    #
#        Copy & rename this file for your own stamp.                                 #
#        Review ALL settings below, pay particular attention to paths/ip's etc..     #
#                                                                                    #
######################################################################################

[Cluster Settings]
# Only developers should set to false.
enable_version_locking=true

# Hardware type, valid options are poweredge, fx
hardware=poweredge

# This pathname must be the full path to the properties file which
# describes the cluster. You should copy *this* sample settings file
# (sample.ini) and the sample properties file (sample.properties) to
# another directory, and customize them for your cluster. Then use the
# path to your customized properties file here.
cluster_nodes_configuration_file=/root/acme.properties

# Indicates if the deploy-overcloud.py script should be run in debug mode
deploy_overcloud_debug=false

# Domain name for the cluster (i.e., mycluster.lab)
domain=domain.net

# DRAC credentials with IPMI privilege for the SAH node
sah_ipmi_user=root
sah_ipmi_password=xxxxxxx

# DRAC credentials with IPMI privilege for the overcloud nodes
ipmi_user=root
ipmi_password=xxxxxxx
# A password to change to on overcloud nodes if desired
new_ipmi_password=

# User for the undercloud/overcloud installation
director_install_user=osp_admin
director_install_user_password=xxxxxxx

# Name of the Overcloud.
# The nodes hostnames will be prepended with the given name and a dash
overcloud_name=overcloud

# Optional : root passord for the overcloud nodes, no password is set if left empty
overcloud_nodes_pwd=

use_internal_repo=false
# Semi-colon ( ; ) separated list of internal repos to use, if needed. Typically
# not used.
internal_repos_locations=CHANGEME_INTERNAL_REPO_URL

# Subscription Manager account info for registering Red Hat subscriptions
subscription_manager_user=xxxxxxx
subscription_manager_password=xxxxxxxxxxxxxx

# The following pool IDs provide different collections of repositories.  
# Each is labeled with possible subscription names. 

# Red Hat Enterprise Linux Self-Supported Business Partner NFR
subscription_manager_pool_sah=xxxxxxxxxxxxxxxxxxxxxxxxxxxx44f5

# Red Hat Enterprise Linux OpenStack Platform Self-Supported Business Partner NFR
subscription_manager_pool_vm_rhel=xxxxxxxxxxxxxxxxxxxxxxxxxxxx454a

# Red Hat Ceph Storage Business Partner Self-Supported NFR, (Physical Node)
subscription_manager_vm_ceph=xxxxxxxxxxxxxxxxxxxxxxxxxxxx7826

subscription_check_retries=20
ntp_servers=0.centos.pool.ntp.org
time_zone=America/Chicago

# Use static ip adresses for the overcloud nodes if set to true (ips need to be defined in the .properties)
# Use dhcp if set to false (ips not required in the .properties)
overcloud_static_ips=true


# Nova public network details
public_api_network=192.168.190.0/24
public_api_vlanid=190
public_api_gateway=192.168.190.1
public_api_netmask=255.255.255.0
public_api_allocation_pool_start=192.168.190.121
public_api_allocation_pool_end=192.168.190.250
name_server=8.8.8.8

# Private API network details
private_api_network=192.168.140.0/24
private_api_vlanid=140
private_api_netmask=255.255.255.0
private_api_allocation_pool_start=192.168.140.121
private_api_allocation_pool_end=192.168.140.250

# Storage network details
storage_network=192.168.170.0/24
storage_vlanid=170
storage_netmask=255.255.255.0
storage_allocation_pool_start=192.168.170.125
storage_allocation_pool_end=192.168.170.250

# Provisioning network details
provisioning_network=192.168.120.0/24
provisioning_vlanid=120
provisioning_netmask=255.255.255.0
provisioning_gateway=192.168.120.1
provisioning_net_dhcp_start=192.168.120.121
provisioning_net_dhcp_end=192.168.120.250
discovery_ip_range=192.168.120.21,192.168.120.120

# Storage cluster network details
storage_cluster_network=192.168.180.0/24
storage_cluster_vlanid=180
storage_cluster_allocation_pool_start=192.168.180.121
storage_cluster_allocation_pool_end=192.168.180.250

# Management network details
# Make sure the SAH node idrac ip defined in the .properties
# is NOT within the allocation pool below.
management_network=192.168.110.0/24
management_vlanid=110
management_netmask=255.255.255.0
management_gateway=192.168.110.1
management_allocation_pool_start=192.168.110.100
management_allocation_pool_end=192.168.110.199

# Tenant network details
# Not used unless you wish to configure Generic Routing Encapsulation (GRE) networks.
tenant_tunnel_network=192.168.130.0/24
tenant_tunnel_network_allocation_pool_start=192.168.130.121
tenant_tunnel_network_allocation_pool_end=192.168.130.250
tenant_tunnel_network_vlanid=130

# Nova Private network details
tenant_vlan_range=201:250


# Use static VIPs ip addresses for the overcloud
use_static_vips=true

# The following VIP settings apply if the above use_static_vips is enabled.

# VIP for the redis service on the Private API api network
# Note that this IP must lie outside the private_api_allocation_pool_start/end
# range
redis_vip=192.168.140.251

# VIP for the provisioning network
# Note that this IP must lie outside the provisioning_net_dhcp_start/end range
provisioning_vip=192.168.120.251

# VIP for the Private API network
# Note that this IP must lie outside the private_api_allocation_pool_start/end
# range
private_api_vip=192.168.140.251

# VIP for the Public API network
# Note that this IP must lie outside the public_api_allocation_pool_start/end
# range
public_api_vip=192.168.190.251

# VIP for the Storage network
# Note that this IP must lie outside the storage_allocation_pool_start/end
# range
storage_vip=192.168.170.251

# VIP for the Storage cluster network
# The Storage Clustering network is not connected to the controller nodes,
# so the VIP for this network must be mapped to the provisioning network
# Note that this IP must lie outside the provisioning_net_dhcp_start/end range
storage_cluster_vip=192.168.120.252



# iDRAC doesn't always play nice due to a bug. Workaround built in the deployer already, but occasionally fails.
# Option below is to use a custom instack.json (i.e., not using idracula) 
use_custom_instack_json=false
custom_instack_json=n/a

# Bonding options configuration by node type
controller_bond_opts=802.3ad miimon=100
compute_bond_opts=802.3ad miimon=100
storage_bond_opts=802.3ad miimon=100


# Overcloud deployment timeout value - default is 120mns, but can be tweaked here if required.
overcloud_deploy_timeout=120


# Interfaces per node type 
controller_bond0_interfaces=em1 p1p1
controller_bond1_interfaces=em2 p1p2
controller_provisioning_interface=em3

compute_bond0_interfaces=em1 p1p1
compute_bond1_interfaces=em2 p1p2
compute_provisioning_interface=em3

storage_bond0_interfaces=em1 p2p1
storage_bond1_interfaces=em2 p2p2
storage_provisioning_interface=em3

# Default driver is DRAC.
use_ipmi_driver=false

# Default introspection method is out-of-band.
# Note that out-of-band introspection is only supported by the DRAC driver.  If
# use_ipmi_driver is set to "true" above then in-band introspection will be
# used regardless of the value below.
use_in_band_introspection=false

# EQLX backend settings, if applicable
enable_eqlx_backend = false
eqlx_backend_name=CHANGEME_EQLX_GROUP_NAME
eqlx_san_ip=CHANGEME_SAN_IP
eqlx_san_login=CHANGEME_SAN_USERNAME
eqlx_san_password=CHANGEME_SAN_PASSWORD
eqlx_ch_login=CHANGEME_CHAP_USERNAME
eqlx_ch_pass=CHANGEME_CHAP_PASSWORD
eqlx_group_n=CHANGEME_EQLX_GROUP_NAME
eqlx_thin_provisioning=true
eqlx_pool=default
eqlx_use_chap=false

# Compellent parameters. See the Software Deployment Guide for description of the parameters.
enable_dellsc_backend=false    
dellsc_backend_name=CHANGEME
dellsc_api_port=3033
dellsc_iscsi_ip_address=CHANGEME
dellsc_iscsi_port=3260
dellsc_san_ip=CHANGEME
dellsc_san_login=CHANGEME
dellsc_san_password=CHANGEME
dellsc_ssn=CHANGEME
dellsc_server_folder=cmpl_iscsi_servers
dellsc_volume_folder=cmpl_iscsi_volumes

# Set to true to enable cinder backend of Ceph for storage.
enable_rbd_backend=true

# Set to true to enable Nova usage of Ceph for ephemeral storage.
# If set to false, Nova uses the storage local to the compute.
enable_rbd_nova_backend=true

# Set to false to disable fencing
# Please refer to the following document for more details on fencing:
# Ready Bundle for Red Hat OpenStack Platform Software Deployment Guide
enable_fencing=true

# Set to true to enable instance HA
# Note : fencing must also be enabled (setting above)
# Please refer to following technical document for more details on Instance HA:
# Ready Bundle for Red Hat OpenStack Platform Software Deployment Guide
enable_instance_ha=false

# The list of RHSM repositories to enable to access the product.  Repos should
# be comma separated.
# Note that this parameter is defaulted as shown below when commented out or
# not specified.  It should not be necessary to change it from the default in
# most cases.
#rhsm_repos=rhel-7-server-openstack-10-rpms,rhel-7-server-openstack-10-devtools-rpms

[Bastion Settings]
cloud_repo_dir=/root/JetPack
rhel_iso=/root/rhel73.iso
# If you want the sanity script to run on deployment completion (Appendix C, etc.), you may do so.
run_sanity=false
# If you want to run Tempest post-deployment, you may do so. The sanity script must also run to create networks for Tempest.
run_tempest=false
tempest_smoke_only=true
# RDO cloud images 
# Available to download @ https://access.redhat.com/downloads/content/191/ver=8/rhel---7/8/x86_64/product-software
discovery_ram_disk_image=/pathto/discovery-ramdisk-7.1.0-39.tar
overcloud_image=/pathto/overcloud-full-7.1.0-39.tar
# if option below is enabled, images will be pulled fom the cdn (and the above x2 settings ignored)
pull_images_from_cdn=true

# Occasionally there can be problems with Subscription Manager
# and a node may be properly registered yet "subscription manager status"
# will return "Unknown"  which will cause checks to fail.
# Setting this to false will skip SM checks to get around this issue.
verify_rhsm_status=true

[Sanity Test Settings]
floating_ip_network=192.168.191.0/24
floating_ip_network_start_ip=192.168.191.20
floating_ip_network_end_ip=192.168.191.59
floating_ip_network_gateway=192.168.191.1
floating_ip_network_vlan=191
sanity_tenant_network=192.168.201.0/24
sanity_user_password=s@n1ty
sanity_user_email=someone@somewhere.com
sanity_key_name=sanity

# The number of instances to spin up in nova.
# Note that this will be limited by the instance quota in OpenStack, which is
# 10 by default.
sanity_number_instances=1
sanity_image_url=http://download.cirros-cloud.net/0.3.3/cirros-0.3.3-x86_64-disk.img
