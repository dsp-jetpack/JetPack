######################################################################################
#                                                                                    #
#        Copy & rename this file for your own stamp 								 #
#		 Review ALL settings below, pay particular attention to paths/ip's etc..     #
#                                                                                    #
######################################################################################

[Cluster Settings]
# only developers should set false
enable_version_locking=false

# This pathname must be the full path to the properties file which
# describes the cluster. You should copy *this* sample settings file
# (settings_sample.ini) and the sample properties file
# (sample.properties) to another directory and customize them for your
# cluster. Then use the path to your customized properties file here.
cluster_nodes_configuration_file=path to your .properties file

# domain name for the cluster, ie. mycluster.lab
domain=domain.net

#drac credentials with ipmi privilege for the nodes
ipmi_user=root
ipmi_password=xxxxxxx

# User for the undercloud/overcloud installation
director_install_user=osp_admin
director_install_user_password=xxxxxxx

use_internal_repo=false
# semi-colon ";" separated list of internal repo's to use, if needed. Typically
# not used.
internal_repos_locations=CHANGEME_INTERNAL_REPO_URL

# subscription manager account info to register Red Hat subscriptions
subscription_manager_user=xxxxxxx
subscription_manager_password=xxxxxxxxxxxxxx

# The following pool id's provide different collections of repositories - 
# each is labeled with possible subscription names 

# Red Hat Enterprise Linux Self-Supported Business Partner NFR
subscription_manager_pool_sah=xxxxxxxxxxxxxxxxxxxxxxxxxxxx44f5

# Red Hat Enterprise Linux OpenStack Platform Self-Supported Business Partner NFR
subscription_manager_pool_vm_rhel=xxxxxxxxxxxxxxxxxxxxxxxxxxxx454a

# Red Hat Ceph Storage Business Partner Self-Supported NFR, (Physical Node)
subscription_manager_vm_ceph=xxxxxxxxxxxxxxxxxxxxxxxxxxxx7826

subscription_check_retries=20
ntp_servers=0.centos.pool.ntp.org
time_zone=America/Chicago


# External network details
external_network=192.168.190.0/24
external_netmask=255.255.255.0
public_gateway=10.21.148.1
external_gateway=192.168.190.1

# Nova public network details
nova_public_network=192.168.190.0/24
public_api_vlanid=190
public_api_netmask=255.255.255.0
external_allocation_pool_start=192.168.190.125
external_allocation_pool_end=192.168.190.224

# Private api network details
private_api_network=192.168.140.0/24
private_api_vlanid=140
private_api_netmask=255.255.255.0
private_api_allocation_pool_start=192.168.140.20
private_api_allocation_pool_end=192.168.140.200

# Storage network details
storage_network=192.168.170.0/24
storage_vlanid=170
storage_netmask=255.255.255.0
storage_allocation_pool_start=192.168.170.20
storage_allocation_pool_end=192.168.170.200

# Provisioning network details
provisioning_network=192.168.120.0/24
provisioning_vlanid=120
provisioning_netmask=255.255.255.0
provisioning_gateway=192.168.120.1
provisioning_net_dhcp_start=192.168.120.125
provisioning_net_dhcp_end=192.168.120.140
discovery_ip_range=192.168.120.141,192.168.120.165

# Storage cluster network details
storage_cluster_network=192.168.180.0/24
storage_cluster_vlanid=180
storage_cluster_allocation_pool_start=192.168.180.20
storage_cluster_allocation_pool_end=192.168.180.200

# Management network details
management_network=192.168.110.0/24
managment_vlanid=110
managment_netmask=255.255.255.0
name_server=8.8.8.8

# Nova Private network details
nova_private_network=192.168.202.0/24
tenant_vlan_range=201:220

# ipmi range for nodes discovery through ipmi (do NOT include the sah)
ipmi_discovery_range_start=192.168.110.101
ipmi_discovery_range_end=192.168.110.110

# idracula/idrac dont always play nice due to a bug. Workaround built in the deployer already but occasionally fails.
# Option below is to use a custom instack.json, i.e not use idracula 
use_custom_instack_json=false
custom_instack_json=n/a

# bonding options configuration by node type (NOTE : TO DO for RDO )
controller_bond_opts=802.3ad miimon=100
compute_bond_opts=802.3ad miimon=100
storage_bond_opts=802.3ad miimon=100


# Overcloud deployment timeout value; default is 120mns but can be tweaked here if required
overcloud_deploy_timeout=120


# Interfaces per node type (currently RDO does not support individual nodes hardware configs)
controller_bond0_interfaces=p4p1 p6p1
controller_bond1_interfaces=p4p2 p6p2
controller_provisioning_interface=em1

compute_bond0_interfaces=p4p1 p6p1
compute_bond1_interfaces=p4p2 p6p2
compute_provisioning_interface=em1

storage_bond0_interfaces=p4p1 p6p1
storage_bond1_interfaces=p4p2 p6p2
storage_provisioning_interface=em1

#default driver is drac.
use_ipmi_driver=true

# EQLx backend settings, if applicable
enable_eqlx_backend = false
eqlx_backend_name=CHANGEME_EQLX_GROUP_NAME
eqlx_san_ip=CHANGEME_SAN_IP
eqlx_san_login=CHANGEME_SAN_USERNAME
eqlx_san_password=CHANGEME_SAN_PASSWORD
eqlx_ch_login=CHANGEME_CHAP_USERNAME
eqlx_ch_pass=CHANGEME_CHAP_PASSWORD
eqlx_group_n=CHANGEME_EQLX_GROUP_NAME
eqlx_thin_provisioning=true
eqlx_pool=default
eqlx_use_chap=false


[Bastion Settings]
rhl72_iso=/pathto/rhel-server-7.2-x86_64-dvd.iso
rhel_install_location=http://192.168.129.223/RH7
sah_kickstart=/pathto/ks.cfg     
cloud_repo_dir=/pathto/cloud_repo
# If you want the sanity script to run on deployment completion (Apendix C etc), you may do so
run_sanity=false
sanity_test=/root/deploy-auto/tests/sanity_test.sh
# If you want to run tempest post deployment, you may do so (sanity must also run to create networks for tempest)
run_tempest=false
tempest_smoke_only=true
# RDO cloud images 
deploy_ram_disk_image=/pathto/deploy-ramdisk-ironic-7.1.0-39.tar
discovery_ram_disk_image=/pathto/discovery-ramdisk-7.1.0-39.tar
overcloud_image=/pathto/overcloud-full-7.1.0-39.tar
